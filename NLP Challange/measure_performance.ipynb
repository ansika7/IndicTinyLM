{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c3852fb3-eaa7-4de8-a01f-3e83006fb714",
   "metadata": {},
   "source": [
    "!pip install datasets\n",
    "!pip install scikit-learn\n",
    "!pip install torchvision\n",
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b7a742-dc1e-426b-bf81-3c9e374a72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\phenix labs\\anaconda3\\envs\\low_resource_nlp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53abc126-834d-4c6a-b52f-86a7eae42e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sentencepiece as spm\n",
    "import os \n",
    "from datasets import Dataset\n",
    "import math\n",
    "import time\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02df6c3-1392-42a4-9eb4-c92a619ed383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class PadCollator:\n",
    "    def __init__(self, pad_id=0, max_length=None):\n",
    "        self.pad_id = pad_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # FIX: safely copy tensors without warnings\n",
    "        input_ids = [f[\"input_ids\"].clone().detach() for f in features]\n",
    "        labels = [f[\"labels\"].clone().detach() for f in features]\n",
    "\n",
    "        # Fixed-length padding or dynamic padding\n",
    "        if self.max_length is not None:\n",
    "            input_ids = [self._pad_to_length(x, self.max_length, self.pad_id) for x in input_ids]\n",
    "            labels = [self._pad_to_length(x, self.max_length, -100) for x in labels]\n",
    "\n",
    "            input_ids = torch.stack(input_ids)\n",
    "            labels = torch.stack(labels)\n",
    "\n",
    "        else:\n",
    "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.pad_id)\n",
    "            labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "\n",
    "    def _pad_to_length(self, tensor, length, pad_value):\n",
    "        if tensor.size(0) < length:\n",
    "            pad_size = length - tensor.size(0)\n",
    "            return torch.cat([tensor, torch.full((pad_size,), pad_value, dtype=tensor.dtype)])\n",
    "        else:\n",
    "            return tensor[:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d084fe72-d638-44e5-b001-6441a75dda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input_ids'].tolist()\n",
    "        self.targets = df['target_ids'].tolist()\n",
    "        self._column_names = [\"input_ids\", \"labels\"]   # <-- added\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.inputs[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def column_names(self):   # <-- added\n",
    "        return self._column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beaa5b6-76dc-4457-9b3c-30fc7243fdd8",
   "metadata": {},
   "source": [
    "## Loading validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdf6d4a-ea24-4d50-98b8-9ac93fbc32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_json(r'dataset/validation_mr.jsonl', lines=True)\n",
    "df_eval = pd.json_normalize(df_eval['row'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57200c07-06b1-4e76-b598-b5cf1bf75cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>औरंगाबाद : प्रतिनिधी 'त्यांनी मला खूप छळलंय.</td>\n",
       "      <td>मला खूप  छळलंय, त्यांनाही छळा</td>\n",
       "      <td>https://www.pudhari.news/news/Aurangabad/Polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>विहिरीमध्ये अज्ञात इसमाचा मृतदेह आढळल्याने खळब...</td>\n",
       "      <td>मोदींची मुख्यमंत्रीपदाची कारकिर्द देशावरचा डाग...</td>\n",
       "      <td>https://www.dainikprabhat.com/modis-chief-mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>मुंबईः काल रात्रीपासून मुंबईत सुरु असलेल्या जो...</td>\n",
       "      <td>महापौर विश्वनाथ महाडेश्वरांंनंतर उद्धव ठाकरेंच...</td>\n",
       "      <td>https://maharashtradesha.com/uddhav-thackerays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>टीम महाराष्ट्र देशा : राज्यात विधानसभा निवडणुक...</td>\n",
       "      <td>शरद पवारांच्या 'या' भूमिकेचा शिवसेनेला बसला दणका</td>\n",
       "      <td>https://maharashtradesha.com/sharad-pawar-said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>पुणे : प्रतिनिधी शालेय विद्यार्थ्यांची सुरक्षि...</td>\n",
       "      <td>शाळा, पालकांमुळे खासगी वाहतूक फोफावणार</td>\n",
       "      <td>https://www.pudhari.news/news/Pune/Private-tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                              input  \\\n",
       "0  1       औरंगाबाद : प्रतिनिधी 'त्यांनी मला खूप छळलंय.   \n",
       "1  2  विहिरीमध्ये अज्ञात इसमाचा मृतदेह आढळल्याने खळब...   \n",
       "2  3  मुंबईः काल रात्रीपासून मुंबईत सुरु असलेल्या जो...   \n",
       "3  4  टीम महाराष्ट्र देशा : राज्यात विधानसभा निवडणुक...   \n",
       "4  5  पुणे : प्रतिनिधी शालेय विद्यार्थ्यांची सुरक्षि...   \n",
       "\n",
       "                                              target  \\\n",
       "0                      मला खूप  छळलंय, त्यांनाही छळा   \n",
       "1  मोदींची मुख्यमंत्रीपदाची कारकिर्द देशावरचा डाग...   \n",
       "2  महापौर विश्वनाथ महाडेश्वरांंनंतर उद्धव ठाकरेंच...   \n",
       "3   शरद पवारांच्या 'या' भूमिकेचा शिवसेनेला बसला दणका   \n",
       "4             शाळा, पालकांमुळे खासगी वाहतूक फोफावणार   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.pudhari.news/news/Aurangabad/Polic...  \n",
       "1  https://www.dainikprabhat.com/modis-chief-mini...  \n",
       "2  https://maharashtradesha.com/uddhav-thackerays...  \n",
       "3  https://maharashtradesha.com/sharad-pawar-said...  \n",
       "4  https://www.pudhari.news/news/Pune/Private-tra...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e62f7-bd2b-4457-868f-d0752149b82f",
   "metadata": {},
   "source": [
    "## Importing tokenizer and tokenizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c160ad16-e9ec-44c4-a3d6-7621e70cd76b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Not found: \"my_tokenizer.model\": No such file or directory Error #2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sp = spm.SentencePieceProcessor()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmy_tokenizer.model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(text):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sp.encode(text, out_type=\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001b[39m, in \u001b[36mSentencePieceProcessor.Load\u001b[39m\u001b[34m(self, model_file, model_proto)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[32m    960\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.LoadFromSerializedProto(model_proto)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001b[39m, in \u001b[36mSentencePieceProcessor.LoadFromFile\u001b[39m\u001b[34m(self, arg)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: Not found: \"my_tokenizer.model\": No such file or directory Error #2"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('my_tokenizer.model')\n",
    "\n",
    "def encode(text):\n",
    "    return sp.encode(text, out_type=int)\n",
    "\n",
    "df_eval['input_ids'] = df_eval['input'].apply(encode)\n",
    "df_eval['target_ids'] = df_eval['target'].apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbe343-43ed-44bf-adc1-fa6322d8fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pad_id = sp.pad_id()\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # logits: (batch, seq, vocab)\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # flatten\n",
    "    preds = preds.reshape(-1)\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    # remove padding tokens\n",
    "    mask = labels != pad_id\n",
    "    preds = preds[mask]\n",
    "    labels = labels[mask]\n",
    "\n",
    "    # compute accuracy\n",
    "    accuracy = (preds == labels).mean()\n",
    "\n",
    "    return {\"token_accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70f727-b04e-4022-91aa-0cd9e20decbf",
   "metadata": {},
   "source": [
    "## Loading GPT2 Model and testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c739d5-2e77-41dd-ada6-cdb75b5b91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"./trained_model2\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=4,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "#eval_dataset = SentencePieceEvalDataset(df_eval, sp, max_length=64)\n",
    "data_collator = PadCollator(pad_id=sp.pad_id(), max_length=64)\n",
    "dataset_eval = TextDataset(df_eval)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  # your PadCollator\n",
    "    eval_dataset=dataset_eval,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17382a89-c55d-44e8-9877-cf20c24332b3",
   "metadata": {},
   "source": [
    "## Calculating perplexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca0c06-20d3-464b-8c9f-828879764eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = math.exp(results[\"eval_loss\"])\n",
    "print(f\"Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a69ce4-b483-4895-b58a-1588d91137de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5272bc8-dbe6-4ba8-9916-7211f445d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency_cpu(model, inputs, *, n_warmup=20, n_runs=100, batch_size=None):\n",
    "    \"\"\"\n",
    "    CPU-only latency measurement.\n",
    "    Returns median, mean, p95, p99, samples/sec.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    if torch.is_tensor(inputs):\n",
    "        sample_input = (inputs,)\n",
    "    else:\n",
    "        sample_input = tuple(inputs)\n",
    "\n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_warmup):\n",
    "            _ = model(*sample_input)\n",
    "\n",
    "    # Measure\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_runs):\n",
    "            t0 = time.time()\n",
    "            _ = model(*sample_input)\n",
    "            t1 = time.time()\n",
    "            times.append((t1 - t0) * 1000)  # ms\n",
    "\n",
    "    arr = np.array(times)\n",
    "    stats = {\n",
    "        \"median_ms\": float(np.median(arr)),\n",
    "        \"mean_ms\": float(np.mean(arr)),\n",
    "        \"p95_ms\": float(np.percentile(arr, 95)),\n",
    "        \"p99_ms\": float(np.percentile(arr, 99)),\n",
    "        \"std_ms\": float(np.std(arr)),\n",
    "        \"samples_per_sec\": None\n",
    "    }\n",
    "\n",
    "    # Per-sample throughput\n",
    "    if batch_size is None:\n",
    "        b = sample_input[0].shape[0]\n",
    "    else:\n",
    "        b = batch_size\n",
    "\n",
    "    stats[\"samples_per_sec\"] = 1000.0 / stats[\"median_ms\"] * b\n",
    "    stats[\"median_ms_per_sample\"] = stats[\"median_ms\"] / b\n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914eb6f-6bd2-4451-9a0b-b7cf48aa0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18().eval()      # CPU by default\n",
    "x = torch.randn(4, 3, 224, 224)       # batch size = 4\n",
    "\n",
    "stats = measure_latency_cpu(model, x, n_runs=50)\n",
    "print(stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e5b14-cde8-465d-8db3-e434facc680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def throughput_vs_batch_cpu(model, input_shape, batch_list=None, n_runs=50):\n",
    "    if batch_list is None:\n",
    "        batch_list = [1, 2, 4, 8, 16]\n",
    "\n",
    "    results = []\n",
    "    for b in batch_list:\n",
    "        x = torch.randn((b,) + tuple(input_shape))\n",
    "        stats = measure_latency_cpu(model, x, n_warmup=5, n_runs=n_runs, batch_size=b)\n",
    "        results.append({\n",
    "            \"batch\": b,\n",
    "            \"samples_per_sec\": stats[\"samples_per_sec\"],\n",
    "            \"median_latency_ms\": stats[\"median_ms\"]\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f09ff4-4306-430b-b798-ec4ad982727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "model = models.resnet18().eval()\n",
    "dummy = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "macs, params = profile(model, inputs=(dummy,), verbose=False)\n",
    "flops = macs * 2\n",
    "print(\"MACs:\", macs)\n",
    "print(\"FLOPs (approx):\", flops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9ae4a-8c59-4fdd-8f58-04d4f7561438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def plot_sample_efficiency(sample_sizes, metrics, *,\n",
    "                           xlabel='# samples', ylabel='val accuracy', logx=True):\n",
    "    x = np.array(sample_sizes)\n",
    "    y = np.array(metrics)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if logx:\n",
    "        plt.xscale('log')\n",
    "    plt.plot(x, y, marker='o', linewidth=2)\n",
    "    plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.title(\"Sample Efficiency Curve\")\n",
    "\n",
    "    raw_auc = auc(x, y)\n",
    "    norm_auc = raw_auc / (x.max() - x.min())\n",
    "    print(\"AUC:\", raw_auc, \"Normalized AUC:\", norm_auc)\n",
    "    plt.show()\n",
    "\n",
    "def power_law(N, a, b, alpha):\n",
    "    return a - b * N**(-alpha)\n",
    "\n",
    "def fit_power_law(sample_sizes, metrics):\n",
    "    popt, _ = curve_fit(power_law, sample_sizes, metrics,\n",
    "                        p0=[max(metrics), max(metrics)-min(metrics), 0.2])\n",
    "    a, b, alpha = popt\n",
    "    print(\"Power-law fit:\", popt)\n",
    "    return popt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328c5b8-358b-4a6a-991c-6754e608f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18().eval()\n",
    "\n",
    "# Latency\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "print(measure_latency_cpu(model, x))\n",
    "\n",
    "# Throughput\n",
    "print(throughput_vs_batch_cpu(model, (3,224,224)))\n",
    "\n",
    "# FLOPs/MACs\n",
    "from thop import profile\n",
    "macs, params = profile(model, inputs=(x,), verbose=False)\n",
    "print(\"MACs:\", macs, \"FLOPs:\", macs*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2c878-a863-4bb6-9204-13af690a5354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596846c-2eb2-470d-b0d3-c62a91a011a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0b6b3-67b3-430e-987f-ca4e78be19ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9981f-99a5-4ca9-b5ae-d7ec06fdadb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02fd96-62c2-4abe-a6f9-70d83a55c853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf46b0-a21d-4c7a-ac76-2977ae7fae48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
