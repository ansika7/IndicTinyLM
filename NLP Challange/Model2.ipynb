{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f51adf69-f062-48b6-ae58-035fbcd9b7a8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "738729b1-7c17-4816-ad76-d8f1d4b97679",
   "metadata": {},
   "source": [
    "# widget for tqdm library\n",
    "!pip install --upgrade ipywidgets jupyter\n",
    "!pip install jupyterlab_widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7da81bd7-e2dc-4dfc-bc8b-b5b446cda793",
   "metadata": {},
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34796fff-ed6b-41a9-a108-254c40eb69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sentencepiece as spm\n",
    "import os \n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import math\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d50246-958d-4e93-8657-e078c4ff7911",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e3832d30-e799-4e42-8600-6b88bae5e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising the dataset because by deafult all the colums get loaded into a single column in the dataframe\n",
    "df = pd.read_json(r'dataset/train_mr.jsonl', lines=True)\n",
    "df = pd.json_normalize(df['row'])\n",
    "\n",
    "df_eval = pd.read_json(r'dataset/validation_mr.jsonl', lines=True)\n",
    "df_eval = pd.json_normalize(df_eval['row'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb527e-a3fa-4bc2-9d34-8f7d9f148cd7",
   "metadata": {},
   "source": [
    "# loading tokenizer and converting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "574cb242-3802-4589-b8dd-5e41a49edb9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(r'model/tokenizer/spm_tokenizer.model')\n",
    "\n",
    "def encode(text):\n",
    "    return sp.encode(text, out_type=int)\n",
    "\n",
    "df['input_ids'] = df['input'].apply(encode)\n",
    "df['target_ids'] = df['target'].apply(encode)\n",
    "\n",
    "df_eval['input_ids'] = df_eval['input'].apply(encode)\n",
    "df_eval['target_ids'] = df_eval['target'].apply(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b3338-9ad5-4261-961b-3dc4b893ed37",
   "metadata": {},
   "source": [
    "# Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a2c3263-e03b-4fed-8d8c-ebc1d73aed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class PadCollator:\n",
    "    def __init__(self, pad_id=0, max_length=None):\n",
    "        self.pad_id = pad_id\n",
    "        self.max_length = max_length  # fixed max length for all batches\n",
    "\n",
    "    def __call__(self, features):\n",
    "        input_ids = [f[\"input_ids\"].clone().detach().long() for f in features]\n",
    "        labels = [f[\"labels\"].clone().detach().long() for f in features]\n",
    "\n",
    "        # Pad each sequence manually to fixed length\n",
    "        if self.max_length is not None:\n",
    "            input_ids = [self._pad_to_length(x, self.max_length, self.pad_id) for x in input_ids]\n",
    "            labels = [self._pad_to_length(x, self.max_length, -100) for x in labels]\n",
    "            input_ids = torch.stack(input_ids)\n",
    "            labels = torch.stack(labels)\n",
    "        else:\n",
    "            # Dynamic padding (default)\n",
    "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.pad_id)\n",
    "            labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "            \n",
    "        attention_mask = (input_ids != self.pad_id).long()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    def _pad_to_length(self, tensor, length, pad_value):\n",
    "        \"\"\"Pad or truncate a tensor to a fixed length.\"\"\"\n",
    "        if tensor.size(0) < length:\n",
    "            pad_size = length - tensor.size(0)\n",
    "            return torch.cat([tensor, torch.full((pad_size,), pad_value, dtype=tensor.dtype)])\n",
    "        else:\n",
    "            return tensor[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d785b321-fb5b-4319-b09c-a55453fac75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input_ids'].tolist()\n",
    "        self.targets = df['target_ids'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.inputs[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "dataset = TextDataset(df)\n",
    "dataset_eval = TextDataset(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31a62078-421e-4f2a-921f-62054528e88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TextDataset"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "451055ad-0533-45c0-9be3-7ffb0f712762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_piece_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1a16f53-18ad-4e32-a32b-9fd9df9abad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=sp.get_piece_size()+10,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=256,\n",
    ")\n",
    "model = GPT2LMHeadModel(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.config.pad_token_id = sp.pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f6eee78-ddcb-4714-950e-38e65cfeb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    report_to='none'\n",
    ")\n",
    "data_collator = PadCollator(pad_id=sp.pad_id(), max_length=64)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=dataset_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af02131b-9975-45de-82bf-5cbe7c5fc24f",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6a6b54c-d55c-49ab-97fb-e51df5373cd8",
   "metadata": {},
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d739351-210a-45ed-8f0b-fa1381a47a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8625' max='8625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8625/8625 09:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.872900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.771600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.719900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>5.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>5.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>5.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>5.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>5.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>5.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>5.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>5.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>5.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>5.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>5.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.714800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>5.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>5.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>5.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>5.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>5.709200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>5.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>5.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>5.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>5.678100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>5.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>5.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>5.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>5.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>5.658300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>5.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>5.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>5.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>5.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>5.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>5.678100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.671300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>5.671900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>5.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>5.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.650700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>5.654700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>5.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>5.630500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>5.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>5.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>5.634800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>5.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>5.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>5.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>5.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>5.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>5.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>5.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.635600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>5.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>5.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>5.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>5.626400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>5.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>5.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>5.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>5.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>5.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.628100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>5.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>5.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>5.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>5.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>5.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>5.636500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8625, training_loss=5.68243210060009, metrics={'train_runtime': 592.2657, 'train_samples_per_second': 58.251, 'train_steps_per_second': 14.563, 'total_flos': 41857744896000.0, 'train_loss': 5.68243210060009, 'epoch': 5.0})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7fccbdfd-8604-45de-b892-5bf0d3398c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(r\"./results/trained_model2\")\n",
    "#tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"my_tokenizer.model\")\n",
    "#tokenizer.save_pretrained(\"./trained_gpt2_sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4531288d-d4c8-4d5b-9cff-594651bc6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phenix Labs\\anaconda3\\envs\\low_resource_nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='325' max='325' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [325/325 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "64cdfda8-242f-4925-84bc-7e401fd84711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 289.39\n"
     ]
    }
   ],
   "source": [
    "perplexity = math.exp(eval_results[\"eval_loss\"])\n",
    "print(f\"Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "422a7d9b-5cee-4c52-9bdb-8d565f86d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.667771816253662, 'eval_runtime': 8.4094, 'eval_samples_per_second': 309.178, 'eval_steps_per_second': 38.647, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d21d5404-bf24-4d09-b9ca-7f09086e5cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 64])\n",
      "Labels shape: torch.Size([1, 64])\n",
      "\n",
      "Decoded input text:\n",
      "सांगली - सांगली शहरातील 100 फुटी रोड परिसरात नवीन वर्षाची सुरुवात तोडफोड, जाळपोळीने झाली.\n",
      "सांगलीत अज्ञातांकडून वाहनांची जाळपोळ\n",
      "\n",
      "Decoded label text:\n",
      "सांगलीत अज्ञातांकडून वाहनांची जाळपोळ\n",
      "\n",
      "Model output (logits) shape: torch.Size([1, 64, 810])\n",
      "\n",
      "Predicted next token: 'व'\n",
      "\n",
      "Generated text:\n",
      " सांगली - सांगली शहरातील 100 फुटी रोड परिसरात नवीन वर्षाची सुरुवात तोडफोड, जाळपोळीने झाली.ोललावीवदसटेकवायलेपूनचाट जलीचाातंजपपार ज \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample = dataset[2]\n",
    "\n",
    "batch = data_collator([sample])\n",
    "\n",
    "input_ids = batch[\"input_ids\"]\n",
    "labels = batch[\"labels\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "\n",
    "\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "print(\"\\nDecoded input text:\")\n",
    "print(sp.decode_ids(input_ids[0].tolist()))\n",
    "\n",
    "decoded_labels = [t for t in labels[0].tolist() if t != -100]\n",
    "print(sp.decode_ids(decoded_labels))\n",
    "\n",
    "print(\"\\nDecoded label text:\")\n",
    "print(sp.decode_ids(decoded_labels))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "logits = outputs.logits\n",
    "print(\"\\nModel output (logits) shape:\", logits.shape)\n",
    "\n",
    "next_token_id = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "next_token = sp.decode_ids(next_token_id[0].tolist())\n",
    "print(\"\\nPredicted next token:\", repr(next_token))\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=input_ids.shape[1] + 30,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    temperature=0.8,\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=sp.pad_id()\n",
    ")\n",
    "generated_text = sp.decode_ids(generated_ids[0].tolist())\n",
    "print(\"\\nGenerated text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ea667161-4c69-4126-9b58-32c555013301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_piece_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bbaf5-01f3-4cf6-a29a-9b470c085fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
